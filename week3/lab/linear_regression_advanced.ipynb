{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "*Adapted from Chapter 3 of [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Classification problem:** supervised learning problem with a categorical response\n",
    "- **Regression problem**: supervised learning problem with a continuous response\n",
    "- **Linear regression:** machine learning model that can be used for regression problems\n",
    "\n",
    "Why are we learning linear regression?\n",
    "\n",
    "- widely used\n",
    "- runs fast\n",
    "- easy to use (no tuning is required)\n",
    "- highly interpretable\n",
    "- basis for many other methods\n",
    "\n",
    "Lesson goals:\n",
    "\n",
    "- Conceptual understanding of linear regression and how it \"works\"\n",
    "- Familiarity with key terminology\n",
    "- Ability to apply linear regression to a machine learning problem using scikit-learn\n",
    "- Ability to interpret model coefficients\n",
    "- Familiarity with different approaches for feature selection\n",
    "- Understanding of three different evaluation metrics for regression\n",
    "- Understanding of linear regression's strengths and weaknesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "- [Statsmodels](http://statsmodels.sourceforge.net/): \"statistics in Python\"\n",
    "    - robust functionality for linear modeling\n",
    "    - useful for teaching purposes\n",
    "    - will not be used in the course outside of this lesson\n",
    "- [scikit-learn](http://scikit-learn.org/stable/): \"machine learning in Python\"\n",
    "    - significantly more functionality for general purpose machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the advertising data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 230.1</td>\n",
       "      <td> 37.8</td>\n",
       "      <td> 69.2</td>\n",
       "      <td> 22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>  44.5</td>\n",
       "      <td> 39.3</td>\n",
       "      <td> 45.1</td>\n",
       "      <td> 10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>  17.2</td>\n",
       "      <td> 45.9</td>\n",
       "      <td> 69.3</td>\n",
       "      <td>  9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 151.5</td>\n",
       "      <td> 41.3</td>\n",
       "      <td> 58.5</td>\n",
       "      <td> 18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td> 180.8</td>\n",
       "      <td> 10.8</td>\n",
       "      <td> 58.4</td>\n",
       "      <td> 12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data into a DataFrame\n",
    "data = pd.read_csv('http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the observations?\n",
    "\n",
    "- Each observation represents **one market** (200 markets in the dataset)\n",
    "\n",
    "What are the features?\n",
    "\n",
    "- **TV:** advertising dollars spent on TV for a single product (in thousands of dollars)\n",
    "- **Radio:** advertising dollars spent on Radio\n",
    "- **Newspaper:** advertising dollars spent on Newspaper\n",
    "\n",
    "What is the response?\n",
    "\n",
    "- **Sales:** sales of a single product in a given market (in thousands of widgets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions about the data\n",
    "\n",
    "You are asked by the company: On the basis of this data, how should we spend our advertising money in the future?\n",
    "\n",
    "You come up with more specific questions:\n",
    "\n",
    "1. Is there a relationship between ads and sales?\n",
    "2. How strong is that relationship?\n",
    "3. Which ad types contribute to sales?\n",
    "4. What is the effect of each ad type of sales?\n",
    "5. Given ad spending in a particular market, can sales be predicted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a **scatter plot** to visualize the relationship between the features and the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO - scatter plot in Seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO - include a \"regression line\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO - scatter plot in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a **scatter matrix** to visualize the relationship between all numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO - scatter MATRIX in Seaborn (see \"pairplot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO - scatter matrix in Pandas (see \"scatter_matrix\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a **correlation matrix** to visualize the correlation between all numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO - compute correlation matrix: call .corr()...but on what? The dataframe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO - display correlation matrix in Seaborn using a heatmap\n",
    "# hint: call sns.heatmap(...) with what as an argument?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple linear regression is an approach for predicting a **continuous response** using a **single feature**. It takes the following form:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x$\n",
    "\n",
    "- $y$ is the response\n",
    "- $x$ is the feature\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_1$ is the coefficient for x\n",
    "\n",
    "$\\beta_0$ and $\\beta_1$ are called the **model coefficients**:\n",
    "\n",
    "- We must \"learn\" the values of these coefficients to create our model.\n",
    "- And once we've learned these coefficients, we can use the model to predict Sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the model coefficients relate to the least squares line?\n",
    "\n",
    "- $\\beta_0$ is the **intercept** (the value of $y$ when $x$=0)\n",
    "- $\\beta_1$ is the **slope** (the change in $y$ divided by change in $x$)\n",
    "\n",
    "Let's estimate the model coefficients for the advertising data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    7.032594\n",
       "TV           0.047537\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### STATSMODELS ### A different way of doing things\n",
    "\n",
    "# create a fitted model\n",
    "lm = smf.ols(formula='Sales ~ TV', data=data).fit()\n",
    "\n",
    "# print the coefficients\n",
    "lm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### SCIKIT-LEARN ### By now you're pros!\n",
    "\n",
    "# TODO:\n",
    "\n",
    "# create X (TV) and y (Sales)\n",
    "\n",
    "\n",
    "# instantiate and fit\n",
    "\n",
    "# print the coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting model coefficients\n",
    "\n",
    "How do we interpret the TV coefficient ($\\beta_1$)?\n",
    "\n",
    "- A \"unit\" increase in TV ad spending is **associated with** a 0.0475 \"unit\" increase in Sales.\n",
    "- Meaning: An additional $1,000 spent on TV ads is **associated with** an increase in sales of 47.5 widgets.\n",
    "- This is not a statement of **causation**.\n",
    "\n",
    "If an increase in TV ad spending was associated with a **decrease** in sales, $\\beta_1$ would be **negative**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model for prediction\n",
    "\n",
    "Let's say that there was a new market where the TV advertising spend was **$50,000**. What would we predict for the Sales in that market?\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1x$$\n",
    "$$y = 7.0326 + 0.0475 \\times 50$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.4076"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually calculate the prediction\n",
    "7.0326 + 0.0475*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.40942557])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### STATSMODELS ###\n",
    "\n",
    "# you have to create a DataFrame since the Statsmodels formula interface expects it\n",
    "X_new = pd.DataFrame({'TV': [50]})\n",
    "\n",
    "# predict for a new observation\n",
    "lm.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.40942557])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SCIKIT-LEARN ###\n",
    "\n",
    "# predict for a new observation\n",
    "linreg.predict(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we would predict Sales of **9,409 widgets** in that market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does the scale of the features matter?\n",
    "\n",
    "Let's say that TV was measured in dollars, rather than thousands of dollars. How would that affect the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-000a13b53cba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TV_dollars'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTV\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data['TV_dollars'] = data.TV * 1000\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4df11387d140>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# create X and y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeature_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'TV_dollars'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSales\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "### SCIKIT-LEARN ###\n",
    "\n",
    "# create X and y\n",
    "feature_cols = ['TV_dollars']\n",
    "X = data[feature_cols]\n",
    "y = data.Sales\n",
    "\n",
    "# instantiate and fit\n",
    "# linreg = LinearRegression()\n",
    "# linreg.fit(X, y)\n",
    "\n",
    "linreg = LinearRegression().fit(X, y)\n",
    "\n",
    "\n",
    "# print the coefficients\n",
    "print linreg.intercept_\n",
    "print linreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we interpret the TV_dollars coefficient ($\\beta_1$)?\n",
    "\n",
    "- A \"unit\" increase in TV ad spending is **associated with** a 0.0000475 \"unit\" increase in Sales.\n",
    "- Meaning: An additional dollar spent on TV ads is **associated with** an increase in sales of 0.0475 widgets.\n",
    "- Meaning: An additional $1,000 spent on TV ads is **associated with** an increase in sales of 47.5 widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.40942557])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for a new observation\n",
    "linreg.predict(50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scale of the features is **irrelevant** for linear regression models, since it will only affect the scale of the coefficients, and we simply change our interpretation of the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: A deeper understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias and variance\n",
    "\n",
    "Linear regression is a low variance/high bias model:\n",
    "\n",
    "- **Low variance:** Under repeated sampling from the underlying population, the line will stay roughly in the same place\n",
    "- **High bias:** The line will rarely fit the data well\n",
    "\n",
    "A closely related concept is **confidence intervals**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence intervals\n",
    "\n",
    "Statsmodels calculates 95% confidence intervals for our model coefficients, which are interpreted as follows: If the population from which this sample was drawn was **sampled 100 times**, approximately **95 of those confidence intervals** would contain the \"true\" coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>6.129719</td>\n",
       "      <td>7.935468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TV</th>\n",
       "      <td>0.042231</td>\n",
       "      <td>0.052843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1\n",
       "Intercept  6.129719  7.935468\n",
       "TV         0.042231  0.052843"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### STATSMODELS ###\n",
    "\n",
    "# print the confidence intervals for the model coefficients\n",
    "lm.conf_int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We only have a **single sample of data**, and not the **entire population of data**.\n",
    "- The \"true\" coefficient is either within this interval or it isn't, but there's no way to actually know.\n",
    "- We estimate the coefficient with the data we do have, and we show uncertainty about that estimate by giving a range that the coefficient is **probably** within.\n",
    "- From Quora: [What is a confidence interval in layman's terms?](http://www.quora.com/What-is-a-confidence-interval-in-laymans-terms/answer/Michael-Hochster)\n",
    "\n",
    "Note: 95% confidence intervals are just a convention. You can create 90% confidence intervals (which will be more narrow), 99% confidence intervals (which will be wider), or whatever intervals you like.\n",
    "\n",
    "A closely related concept is **hypothesis testing**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing and p-values\n",
    "\n",
    "General process for hypothesis testing:\n",
    "\n",
    "- You start with a **null hypothesis** and an **alternative hypothesis** (that is opposite the null).\n",
    "- You check whether the data supports **rejecting the null hypothesis** or **failing to reject the null hypothesis**.\n",
    "\n",
    "For model coefficients, here is the conventional hypothesis test:\n",
    "\n",
    "- **null hypothesis:** There is no relationship between TV ads and Sales (and thus $\\beta_1$ equals zero)\n",
    "- **alternative hypothesis:** There is a relationship between TV ads and Sales (and thus $\\beta_1$ is not equal to zero)\n",
    "\n",
    "How do we test this hypothesis?\n",
    "\n",
    "- The **p-value** is the probability that the relationship we are observing is occurring purely by chance.\n",
    "[video](https://www.youtube.com/watch?v=eyknGvncKLw)\n",
    "[Khan](https://www.youtube.com/watch?v=HTZ8YKgD0MI)\n",
    "- If the 95% confidence interval for a coefficient **does not include zero**, the p-value will be **less than 0.05**, and we will reject the null (and thus believe the alternative).\n",
    "- If the 95% confidence interval **includes zero**, the p-value will be **greater than 0.05**, and we will fail to reject the null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    1.406300e-35\n",
       "TV           1.467390e-42\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### STATSMODELS ###\n",
    "\n",
    "# print the p-values for the model coefficients\n",
    "lm.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, a p-value less than 0.05 is one way to decide whether there is **likely** a relationship between the feature and the response. In this case, the p-value for TV is far less than 0.05, and so we **believe** that there is a relationship between TV ads and Sales.\n",
    "\n",
    "Note that we generally ignore the p-value for the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well does the model fit the data?\n",
    "\n",
    "R-squared:\n",
    "\n",
    "- A common way to evaluate the overall fit of a linear model\n",
    "- Defined as the **proportion of variance explained**, meaning the proportion of variance in the observed data that is explained by the model\n",
    "- Also defined as the reduction in error over the **null model**, which is the model that simply predicts the mean of the observed response\n",
    "- Between 0 and 1, and higher is better\n",
    "\n",
    "Here's an example of what R-squared \"looks like\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![R-squared](images/r_squared.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the R-squared value for our simple linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61187505085007099"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### STATSMODELS ###\n",
    "\n",
    "# print the R-squared value for the model\n",
    "lm.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61187505085007099"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SCIKIT-LEARN ###\n",
    "\n",
    "# calculate the R-squared value for the model\n",
    "y_pred = linreg.predict(X)\n",
    "metrics.r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The threshold for a **\"good\" R-squared value** is highly dependent on the particular domain.\n",
    "- R-squared is more useful as a tool for **comparing models**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Multiple Linear Regression\n",
    "\n",
    "Simple linear regression can easily be extended to include multiple features, which is called **multiple linear regression**:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n$\n",
    "\n",
    "Each $x$ represents a different feature, and each feature has its own coefficient:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1 \\times TV + \\beta_2 \\times Radio + \\beta_3 \\times Newspaper$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.93888936946\n",
      "[ 0.04576465  0.18853002 -0.00103749]\n"
     ]
    }
   ],
   "source": [
    "### SCIKIT-LEARN ###\n",
    "\n",
    "# create X and y\n",
    "feature_cols = ['TV', 'Radio', 'Newspaper']\n",
    "X = data[feature_cols]\n",
    "y = data.Sales\n",
    "\n",
    "# instantiate and fit\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "\n",
    "# print the coefficients\n",
    "print linreg.intercept_\n",
    "print linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TV', 0.04576464545539765),\n",
       " ('Radio', 0.18853001691820462),\n",
       " ('Newspaper', -0.0010374930424762799)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pair the feature names with the coefficients\n",
    "zip(feature_cols, linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given amount of Radio and Newspaper spending, an increase of $1000 in **TV** spending is associated with an **increase in Sales of 45.8 widgets**.\n",
    "\n",
    "For a given amount of TV and Newspaper spending, an increase of $1000 in **Radio** spending is associated with an **increase in Sales of 188.5 widgets**.\n",
    "\n",
    "For a given amount of TV and Radio spending, an increase of $1000 in **Newspaper** spending is associated with an **decrease in Sales of 1.0 widgets**. How could that be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "How do I decide **which features to include** in a linear model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using p-values\n",
    "\n",
    "We could try a model with all features, and only keep features in the model if they have **small p-values**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept    1.267295e-17\n",
      "TV           1.509960e-81\n",
      "Radio        1.505339e-54\n",
      "Newspaper    8.599151e-01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "### STATSMODELS ###\n",
    "\n",
    "# create a fitted model with all three features\n",
    "lm = smf.ols(formula='Sales ~ TV + Radio + Newspaper', data=data).fit()\n",
    "\n",
    "# print the p-values for the model coefficients\n",
    "print lm.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates we would reject the null hypothesis for **TV and Radio** (that there is no association between those features and Sales), and fail to reject the null hypothesis for **Newspaper**. Thus, we would keep TV and Radio in the model.\n",
    "\n",
    "However, this approach has **drawbacks**:\n",
    "\n",
    "- Linear models rely upon a lot of **assumptions** (such as the features being independent), and if those assumptions are violated (which they usually are), p-values are less reliable.\n",
    "- Using a p-value cutoff of 0.05 means that if you add 100 features to a model that are **pure noise**, 5 of them (on average) will still be counted as significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using R-squared\n",
    "\n",
    "We could try models with different sets of features, and **compare their R-squared values**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89719426108289557"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R-squared value for the model with two features\n",
    "lm = smf.ols(formula='Sales ~ TV + Radio', data=data).fit()\n",
    "lm.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89721063817895219"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R-squared value for the model with three features\n",
    "lm = smf.ols(formula='Sales ~ TV + Radio + Newspaper', data=data).fit()\n",
    "lm.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would seem to indicate that the best model includes **all three features**. Is that right?\n",
    "\n",
    "- R-squared will always increase as you add more features to the model, even if they are **unrelated** to the response.\n",
    "- As such, using R-squared as a model evaluation metric can lead to **overfitting**.\n",
    "- **Adjusted R-squared** is an alternative that penalizes model complexity (to control for overfitting), but it generally [under-penalizes complexity](http://scott.fortmann-roe.com/docs/MeasuringError.html).\n",
    "\n",
    "As well, R-squared depends on the same assumptions as p-values, and it's less reliable if those assumptions are violated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using train/test split (or cross-validation)\n",
    "\n",
    "A better approach to feature selection!\n",
    "\n",
    "- They attempt to directly estimate how well your model will **generalize** to out-of-sample data.\n",
    "- They rely on **fewer assumptions** that linear regression.\n",
    "- They can easily be applied to **any model**, not just linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics for regression problems\n",
    "\n",
    "Evaluation metrics for classification problems, such as **accuracy**, are not useful for regression problems. We need evaluation metrics designed for comparing **continuous values**.\n",
    "\n",
    "Let's create some example numeric predictions, and calculate three common evaluation metrics for regression problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define true and predicted response values\n",
    "y_true = [100, 50, 30, 20]\n",
    "y_pred = [90, 50, 50, 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Absolute Error** (MAE) is the mean of the absolute value of the errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "print metrics.mean_absolute_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Squared Error** (MSE) is the mean of the squared errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150.0\n"
     ]
    }
   ],
   "source": [
    "print metrics.mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Root Mean Squared Error** (RMSE) is the square root of the mean of the squared errors:\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.2474487139\n"
     ]
    }
   ],
   "source": [
    "print np.sqrt(metrics.mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing these metrics:\n",
    "\n",
    "- **MAE** is the easiest to understand, because it's the average error.\n",
    "- **MSE** is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n",
    "- **RMSE** is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
    "\n",
    "All of these are **loss functions**, because we want to minimize them.\n",
    "\n",
    "Here's an additional example, to demonstrate how MSE/RMSE punish larger errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "20.0\n"
     ]
    }
   ],
   "source": [
    "# same true values as above\n",
    "y_true = [100, 50, 30, 20]\n",
    "\n",
    "# new set of predicted values\n",
    "y_pred = [60, 50, 30, 20]\n",
    "\n",
    "# MAE is the same as before\n",
    "print metrics.mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# RMSE is larger than before\n",
    "print np.sqrt(metrics.mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using train/test split for feature selection\n",
    "\n",
    "Let's use train/test split with RMSE to decide whether Newspaper should be kept in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a function that accepts X and y and computes testing RMSE\n",
    "def train_test_rmse(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_pred = linreg.predict(X_test)\n",
    "    return np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4046514230328948"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include Newspaper\n",
    "feature_cols = ['TV', 'Radio', 'Newspaper']\n",
    "X = data[feature_cols]\n",
    "train_test_rmse(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3879034699382886"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude Newspaper\n",
    "feature_cols = ['TV', 'Radio']\n",
    "X = data[feature_cols]\n",
    "train_test_rmse(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing linear regression with other models\n",
    "\n",
    "Advantages of linear regression:\n",
    "\n",
    "- Simple to explain\n",
    "- Highly interpretable\n",
    "- Model training and prediction are fast\n",
    "- No tuning is required (excluding regularization)\n",
    "- Features don't need scaling\n",
    "- Can perform well with a small number of observations\n",
    "\n",
    "Disadvantages of linear regression:\n",
    "\n",
    "- Presumes a linear relationship between the features and the response\n",
    "- Performance is (generally) not competitive with the best supervised learning methods due to high bias\n",
    "- Sensitive to irrelevant features\n",
    "- Can't automatically learn feature interactions"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
